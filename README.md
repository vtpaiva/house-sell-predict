# house-sell-predict

(All the notebooks codes, in `notebooks` folder, are also documented)

#### Portugu√™s üáßüá∑

---

## **Objetivo**

O objetivo desta an√°lise √© **prever se um usu√°rio de um site imobili√°rio comprar√° uma casa** com base nos dados de seu perfil. Isso inclui vari√°veis como **idade**, **renda anual**, **g√™nero**, **tempo gasto no site** e **se o usu√°rio clicou em um an√∫ncio**.

## **Vis√£o Geral do Dataset**
O dataset cont√©m as seguintes colunas:
- **Idade**: Idade do usu√°rio.
- **Renda Anual ($)**: Renda anual do usu√°rio em d√≥lares.
- **G√™nero**: G√™nero do usu√°rio (Feminino ou Masculino).
- **Tempo no Site (min)**: Tempo gasto navegando no site, em minutos.
- **An√∫ncio Clicado**: Indica se o usu√°rio clicou em um an√∫ncio (Sim ou N√£o).
- **Compra**: Vari√°vel alvo indicando se o usu√°rio comprou uma casa (1 para Sim, 0 para N√£o).

## **An√°lise e Resultados**

Para compreender plenamente os resultados finais e as conclus√µes, **cada etapa do processo ser√° rigorosamente documentada e analisada de forma cr√≠tica.**

### **An√°lise Explorat√≥ria de Dados (EDA)**

* O dataset apresentou um **desbalanceamento** em rela√ß√£o √† vari√°vel alvo, com uma propor√ß√£o de **67% (n√£o compraram) - 33% (compraram).** Consequentemente, **m√©tricas adicionais al√©m da acur√°cia simples foram consideradas.** Durante o treinamento do modelo, foi utilizada a **m√©trica ROC AUC,** enquanto o **F1-score, recall e precis√£o** foram usados para avaliar o desempenho nas classes alvo.

* O dataset continha caracter√≠sticas com **escalas variadas**, exigindo **padroniza√ß√£o** posteriormente para mitigar seu impacto.

* O dataset inclu√≠a **2 caracter√≠sticas categ√≥ricas e 3 num√©ricas.** No entanto, ao visualizar os dados, observou-se que **a renda anual apresentava um comportamento mais pr√≥ximo de uma caracter√≠stica discreta.** Essa observa√ß√£o levou √† sua **convers√£o em uma caracter√≠stica discreta baseada em quantis.**

* As **caracter√≠sticas num√©ricas n√£o apresentavam uma distribui√ß√£o explicitamente conhecida**, sugerindo o uso de **m√©todos n√£o param√©tricos para compara√ß√£o de modelos.**

* Durante a **an√°lise de correla√ß√£o**, o **m√©todo de Pearson** revelou que as caracter√≠sticas mais fortemente correlacionadas com a vari√°vel alvo eram **tempo gasto no site e idade.** Surpreendentemente, **a renda anual apresentou a correla√ß√£o mais negativa.**

* Utilizando o **m√©todo de Spearman**, as correla√ß√µes permaneceram semelhantes √†s observadas com o m√©todo de Pearson. Essa consist√™ncia sugere um **baixo impacto de outliers** e a aus√™ncia de **fortes correla√ß√µes n√£o lineares.**

* Os **gr√°ficos KDE e de dispers√£o** revelaram **distribui√ß√µes vari√°veis nas caracter√≠sticas de idade e renda anual dependendo do r√≥tulo final.** Essa observa√ß√£o sugere um **certo grau de relev√¢ncia dessas caracter√≠sticas** na determina√ß√£o da probabilidade de compra.

* Com base nos **gr√°ficos de barras que ilustraram a propor√ß√£o de compras de casas para cada valor das caracter√≠sticas categ√≥ricas**, observou-se que nem o **g√™nero nem o clique em an√∫ncios apresentaram despropor√ß√£o significativa** nas taxas de compra em rela√ß√£o ao equil√≠brio original da vari√°vel alvo. No entanto, **a renda anual demonstrou certo n√≠vel de proporcionalidade inversa** com a probabilidade de compra.

### **Pr√©-processamento de Dados**

* O dataset original continha **valores ausentes e inconsistentes.** Para lidar com isso, os **valores inconsistentes foram substitu√≠dos por valores nulos.** Posteriormente, todos os **valores ausentes foram imputados utilizando um algoritmo baseado em KNN.**

* A **caracter√≠stica de renda anual,** apresentando uma distribui√ß√£o semelhante a uma vari√°vel discreta, foi **convertida em uma caracter√≠stica categ√≥rica baseada em quantis.** Essa abordagem foi adotada para **melhorar a interpretabilidade e facilitar a an√°lise.**

* Devido √†s **escalas variadas** presentes no dataset, as caracter√≠sticas foram **padronizadas** na etapa anterior ao treinamento para **mitigar essas diferen√ßas.**

* Em uma tentativa de **aproximar a distribui√ß√£o das vari√°veis cont√≠nuas de uma distribui√ß√£o Gaussiana,** foi aplicada a **fun√ß√£o logar√≠tmica,** mas **n√£o trouxe mudan√ßas significativas.**

### **Constru√ß√£o do Modelo**

* Durante o treinamento, o **m√©todo de valida√ß√£o cruzada** foi empregado para **aumentar a robustez do modelo.** Utilizando as **pontua√ß√µes m√©dias dos testes,** avaliou-se a **varia√ß√£o do desempenho da hip√≥tese com base em diferentes configura√ß√µes de hiperpar√¢metros.**

* O **algoritmo de Regress√£o Log√≠stica** inicialmente demonstrou um **alto grau de underfitting,** indicando que **limites de decis√£o lineares sozinhos s√£o insuficientes** para capturar os **padr√µes complexos necess√°rios para uma pontua√ß√£o satisfat√≥ria.**

* Para permitir que a **Regress√£o Log√≠stica** capturasse alguns **padr√µes n√£o lineares,** foi aplicado o m√©todo de **pr√©-processamento de caracter√≠sticas polinomiais** ao dataset. No entanto, o **vi√©s da hip√≥tese permaneceu consideravelmente alto,** e conforme o **grau polinomial aumentava, o n√≠vel de overfitting tamb√©m escalava.**

* O **algoritmo Random Forest** inicialmente exibiu um **alto n√≠vel de overfitting** com **vari√¢ncia moderada e vi√©s significativo.** No entanto, com a aplica√ß√£o de **t√©cnicas de regulariza√ß√£o, o overfitting foi mitigado,** embora o **vi√©s permanecesse alto.**

* Por fim, foi realizada uma **valida√ß√£o cruzada com hiperpar√¢metros selecionados aleatoriamente** no modelo Random Forest, mas os **resultados n√£o mostraram melhora significativa.**

### **Avalia√ß√£o do Modelo**

* Com **ROC AUC como a principal m√©trica de avalia√ß√£o,** as hip√≥teses foram avaliadas com base em seu **vi√©s e vari√¢ncia** utilizando o **histograma de pontua√ß√£o m√©dia dos testes da valida√ß√£o cruzada.**

* Foram realizadas **avalia√ß√µes espec√≠ficas por classe** utilizando o **relat√≥rio de classifica√ß√£o,** com foco em **recall, precis√£o e F1-score** como as principais m√©tricas de an√°lise.

* Devido √† **falta de uma distribui√ß√£o expl√≠cita de dados,** foi aplicado o **m√©todo de reamostragem bootstrap, aproveitando sua natureza n√£o param√©trica.** Isso envolveu o c√°lculo do **ROC AUC em v√°rias reamostragens,** proporcionando uma **visualiza√ß√£o mais clara da varia√ß√£o, vi√©s e pontua√ß√µes m√©dias das hip√≥teses.**

* Al√©m disso, o **teste de Nemenyi, um m√©todo de avalia√ß√£o n√£o param√©trico,** foi empregado para verificar se **existiam diferen√ßas significativas entre os modelos.** A **hip√≥tese Random Forest** demonstrou as **maiores diferen√ßas entre os modelos.**

* Os **modelos Random Forest** foram considerados os **melhores no geral** devido ao seu **desempenho superior nas principais m√©tricas avaliadas.**

### **Interpreta√ß√£o dos Resultados**

* Em ambos os modelos, as **caracter√≠sticas mais importantes foram o tempo gasto no site e a idade,** destacando sua **relev√¢ncia para as previs√µes.**

* O **modelo baseado em Regress√£o Log√≠stica** apresentou um **n√≠vel mais consistente de import√¢ncia entre todas as caracter√≠sticas,** enquanto os **outros modelos atribu√≠ram maior import√¢ncia ao tempo gasto no site e √† idade.**

### **Recomenda√ß√µes para Melhorias**

* Experimentar com **algoritmos de treinamento capazes de criar limites de segmenta√ß√£o mais complexos** para extrair padr√µes que **Regress√£o Log√≠stica e Random Forest podem ter perdido.**

* Explorar **hiperpar√¢metros alternativos e m√©todos de regulariza√ß√£o** para alcan√ßar um **equil√≠brio entre alto ajuste aos dados e manuten√ß√£o da capacidade de generaliza√ß√£o.**

## **Conclus√£o**

A an√°lise destacou a **import√¢ncia de caracter√≠sticas como tempo gasto no site e idade** na previs√£o de compras de casas. A Regress√£o Log√≠stica **enfrentou dificuldades com underfitting,** enquanto o Random Forest **demonstrou melhor desempenho,** apesar de algum vi√©s. M√©todos de valida√ß√£o cruzada e avalia√ß√µes n√£o param√©tricas confirmaram o **Random Forest como o melhor modelo** com base nas principais m√©tricas, mas a explora√ß√£o de **algoritmos avan√ßados e t√©cnicas de regulariza√ß√£o** ainda √© necess√°ria para melhorar a generaliza√ß√£o e capturar **padr√µes mais complexos.**

#### English üá∫üá∏

---

## **Objective**

The goal of this analysis is to **predict whether a user of a real estate website will purchase a house** based on their profile data. This includes variables such as **age**, **annual income**, **gender**, **time spent on the site**, and **whether the user clicked on an ad**.

## **Dataset Overview**
The dataset contains the following columns:
- **Age**: User's age.
- **Annual Income ($)**: User's annual income in dollars.
- **Gender**: User's gender (Female or Male).
- **Time on Site (min)**: Time spent browsing the website in minutes.
- **Ad Clicked**: Whether the user clicked on an advertisement (Yes or No).
- **Purchase**: Target variable indicating whether the user purchased a house (1 for Yes, 0 for No).

## **Analysis and Results**

To fully grasp the final results and conclusions, **every step of the process will be thoroughly documented and critically discussed.**

### **Exploratory Data Analysis (EDA)**

* The dataset exhibited **imbalance** with respect to the target feature, with a **67% (did not buy) - 33% (did buy)** proportion. Consequently, **additional evaluation metrics beyond simple accuracy were considered.** During model training, the **ROC AUC metric** was utilized, while the **F1-score, recall, and precision** were used to evaluate performance within the target classes.

* The dataset contained features with **varying scales**, necessitating **standardization** later in the process to mitigate its impact.

* The dataset included **2 categorical features and 3 numeric features.** However, upon visualizing the data, it was observed that **annual income exhibited behavior more similar to a discrete feature.** This observation prompted its **conversion to a discrete feature based on quantiles.**

* The **numeric features lacked an explicitly known distribution**, suggesting the use of **non-parametric methods for model comparison.**

* During the **correlation analysis**, the **Pearson method** revealed that the features most strongly correlated with the target column were **time spent on site and age.** Surprisingly, **annual income exhibited the most negative correlation.**

* Using the **Spearman method**, the correlations remained similar to those observed with the Pearson method. This consistency suggests a **low impact from outliers** and an absence of **strong non-linear correlations.**

* The **KDE plots** and **scatter plots** revealed **varying distributions in the age and annual income features depending on the final label.** This observation suggests a **certain degree of relevance for these features** in determining the likelihood of a purchase.

* Based on the **bar plots illustrating the ratio of house purchases for each value of the categorical features,** it was observed that neither **gender nor whether an ad was clicked showed significant disproportion** in the purchase rates relative to the original target column's balance. However, **annual income demonstrated some level of inverse proportionality** with the likelihood of making a purchase.

### **Data Preprocessing**

* The original dataset contained **missing and inconsistent values.** To address this, **inconsistent values were replaced with null values.** Subsequently, all **missing values were imputed using a KNN-based algorithm.**

* The **annual income feature**, exhibiting a distribution resembling a discrete variable, was **converted into a categorical feature based on quantiles.** This approach was adopted to **enhance interpretability and facilitate analysis.**

* Due to the **varying scales** present in the dataset, the features were **standardized** in the step prior to training to **mitigate their differences.**

* In an attempt to **make the continuous variables' distribution closer to a Gaussian distribution,** the **logarithm function** was applied, but **did not make a significant difference.**

### **Model Building**

* During the training step, the **cross-validation method** was employed to **enhance the model's robustness.** Using the **mean test scores,** it evaluated the **performance variation of the hypothesis based on different hyperparameter configurations.**

* The **Logistic Regression algorithm** initially demonstrated a **high degree of underfitting,** indicating that **linear decision boundaries alone are insufficient** to capture the **complex patterns needed for a satisfactory score.**

* To enable **Logistic Regression** to capture some **non-linear patterns,** the **polynomial features preprocessing method** was applied to the dataset. However, the **hypothesis bias remained considerably high**, and as the **polynomial degree increased, the level of overfitting also escalated.**

* The **Random Forest algorithm** initially exhibited a **high level of overfitting** with **moderate variance and significant bias.** However, with the application of **regularization techniques, overfitting was mitigated,** though the **bias remained high.**

* Finally, a **cross-validation with randomly selected hyperparameters** was performed on the Random Forest model, but the **results showed no significant improvement.**

### **Model Evaluation**

* With **ROC AUC as the primary evaluation metric**, the hypotheses were assessed based on their **bias and variance** using the **mean test score histogram from cross-validation.**

* **Class-specific evaluations** were conducted using the **classification report,** focusing on **recall, precision, and F1-score** as the main metrics for analysis.

* Due to the **lack of an explicit data distribution,** the **bootstrap resampling method, leveraging its non-parametric nature,** was applied. This involved calculating the **ROC AUC across multiple resamples,** providing a **clearer visualization of hypothesis variation, bias, and mean scores.**

* Additionally, the **Nemenyi test, a non-parametric evaluation method,** was employed to verify whether **significant differences existed between the models.** The **Random Forest hypothesis** demonstrated the **largest differences among the models.**

* The **Random Forest models** were considered the **best overall** due to their **superior performance on the primary metrics evaluated.**

### **Interpretation of Results**

* In both models, the **most important features were time spent on the website and age,** highlighting their **significance in making predictions.**

* The **Linear Regression-based model** exhibited a **more consistent level of importance across all features,** whereas the **other models assigned greater importance to time spent on the website and age.**

### **Recommendations for Improvement**

* Experiment with **training algorithms capable of creating more complex segmentation boundaries** to extract patterns that **Logistic Regression and Random Forest may have missed.**

* Explore **alternative hyperparameters and regularization methods** to achieve a **balance between high fitting to the data and maintaining generalization capabilities.**

## **Conclusion**

The analysis highlighted the **importance of features like time spent on the website and age** in predicting house purchases. Logistic Regression **struggled with underfitting,** while Random Forest **demonstrated better performance** despite some bias. Cross-validation and non-parametric methods confirmed **Random Forest as the best model** based on key metrics, but further exploration of **advanced algorithms and regularization techniques** is needed to improve generalization and capture **more complex patterns.**